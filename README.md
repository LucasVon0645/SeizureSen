# SeizureSen: Predicting Seizures in Dogs Using iEEG

**SeizureSen** is a project developed at **Technische UniversitÃ¤t Darmstadt** in the seminar **Data Science II** during the **Winter Semester 24/25**. Its goal is to present a model which allows the prediction of seizures in dogs using intracranial EEG (iEEG) signals. A machine learning model is used to classify the preictal phase of brain activity, leveraging the dataset from the [American Epilepsy Society Seizure Prediction Challenge](https://www.kaggle.com/competitions/seizure-prediction/overview). A web application is also provided in this project as a demonstration tool. It features real-time data visualization and classification. In the frontend, a warning is given when a preictal phase is detected in the iEEG data, so that dog owners could possibly to take timely interventions

## Dataset

The project leverages the dataset provided by the **American Epilepsy Society Seizure Prediction Challenge** on Kaggle, which contains intracranial EEG recordings from both dogs and humans with epilepsy. While the dataset includes data from both species, this project specifically focuses on recordings from dogs, aligning with its goal of developing a seizure prediction application tailored for canine use.

## Problem Description

Epileptic brain activity is divided into four states:

1. **Interictal**: Normal baseline activity between seizures.
2. **Preictal**: Brain state leading up to a seizure.
3. **Ictal**: Active seizure phase.
4. **Postictal**: Recovery phase after a seizure.

The challenge is to accurately identify the **preictal state**, which can help forecast seizures in dogs. This enables their owners to take timely interventions, mitigate risks, and manage the effects of epilepsy more effectively.

## Features

- **Machine Learning Models**: Classifier for preictal vs. interictal states in iEEG signals.
- **Customizable Pipelines**: Easily adapt algorithms and preprocessing steps.
- **User Interface**: Intuitive interface for testing the model and visualizing prediction results. It provides a simulation of the system.

## Technologies Used

1. TensorFlow/Keras: For deep learning-based classification.
2. Streamlit: For interactive frontend visualization.
3. SciPy: For signal processing and feature extraction.
4. Statsmodels: For conducting hypothesis tests.


## Getting Started

### Prerequisites

Ensure you have Python installed (>=3.8). You can download it from [python.org](https://www.python.org/downloads/).

### Clone the Repository

```bash
git clone https://github.com/LucasVon0645/SeizureSen.git
cd SeizureSen
```

### Setting Up a Virtual Environment

1. Create a virtual environment (optional but recommended):

```bash
# Using venv (Python 3.X)
python -m venv env

# Activate the virtual environment
# On Windows
.\env\Scripts\Activate
# On macOS/Linux
source env/bin/activate
```

2.Install Dependencies

```bash
pip install -r requirements.txt
```

### Running the Application

1. Ensure the virtual environment is activated.
2. Ensure a pre-trained model is available in /models.
3. Run the command below in the **root directory of the project**:

```bash
streamlit run main.py
```

## Training and Testing a Model

1. Create a ".json" config file in the "models/config" directory with the necessary hyperparameters and training settings.
2. Ensure the preprocessed data is available in the "data/preprocessed" directory.
3. Adjust the paths for the model configuration and the preprocessed data in "src/Train/train.py". Adjust the names of the preprocessed data if necessary.
4. Run the script "src/Train/train.py".

As a result, *a new folder with the model parameters and results will be created in the "models" directory*. The new folder name is determined by the model path set in the ".json" configuration file.

The class `ModelTrainer` available in "src/Train/ModelTrainer.py" is used for performing the training, cross validation and evaluation tasks.
Two models are provided in the directory "src/Models". Both use a multi-view convolution neural network over time and frequency domain features. However, one uses an Attention mechanism and the other not.

Note: The preprocessed data can be generated by the script "src/Preprocessing/preprocess.py". A sample example is also available in this [link](https://hessenbox.tu-darmstadt.de/getlink/fiGLnzqnw4M42xLFe2ocB593/preprocessed_data).

### Model configuration file

A json configuration file is used to set some training parameters.

The following fields define the configuration used for training the model in Keras:

- `nb_filter` (int): Number of filters in the convolutional layers.
- `l2` (float): L2 regularization strength to prevent overfitting.
- `dropout` (float): Dropout rate applied to layers for regularization.
- `learning_rate` (float): Learning rate for the optimizer.
- `model_time_steps` (int): Number of time steps used as input to the model.
- `channels` (int): Number of input channels.
- `fft_bins` (int): Number of frequency bins used in FFT preprocessing. It must match the ones used in the preprocessing data.
- `pca_bins` (int): Number of principal components retained after PCA transformation. It must match the ones used in the preprocessing data.
- `nn_time_output` (int): Output size in the time dimension after the neural network processing.
- `nn_freq_output` (int): Output size in the frequency dimension after the neural network processing.
- `batch_size` (int): Number of samples per training batch.
- `use_early_exits` (bool): Enables multiple early exits in the model, allowing intermediate predictions at different stages.
- `augmentation_strategy` (str): Data augmentation strategy applied to the training dataset. Options: "SMOTE", "ADASYN", or null (no augmentation).
- `preictal_class_weight` (float or null): Class weight for the preictal class. Used in model.fit() as class_weight to indicate the importance of the preictal class during training. If null, no class weighting is applied.
- `nb_epoch` (int): Total number of training epochs.
- `name` (str): Name of the model class to be used. Possible values are, e.g. "MultiViewConvModel".
- `model_path` (str): Path where the trained model and the training/cross-validation/evaluation results are saved.

### Metrics

The following scores are calculated for evaluating a model's performance.

- overall accuracy
- precision (for both classes)
- recall (for both classes)
- f1-score (for both classes)
- AUC of the Receiver operating characteristic

## Important remarks

The model, training, and preprocessing steps were inspired by the paper [Liu et al., 2019](https://doi.org/10.1109/ACCESS.2019.2955285). The code for this model can be found in the [GitHub repository](https://github.com/uobinxiao/seizure-prediction).

## References

1. C. -L. Liu, B. Xiao, W. -H. Hsaio and V. S. Tseng, "Epileptic Seizure Prediction With Multi-View Convolutional Neural Networks," in IEEE Access, vol. 7, pp. 170352-170361, 2019, doi: [10.1109/ACCESS.2019.2955285](https://doi.org/10.1109/ACCESS.2019.2955285).

2. Xiao, B. (2025). Seizure Prediction Repository. GitHub repository. Retrieved February 3, 2025, from [https://github.com/uobinxiao/seizure-prediction](https://github.com/uobinxiao/seizure-prediction).

3. Chollet, F. (2015). Keras. GitHub repository. Retrieved February 3, 2025, from [https://github.com/keras-team/keras](https://github.com/keras-team/keras).

4. Abadi, M., Agarwal, A., Barham, P., et al. (2016). TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems. TensorFlow. Retrieved February 3, 2025, from [https://www.tensorflow.org/](https://www.tensorflow.org/).

5. Streamlit Team. (2021). Streamlit: The fastest way to build and share data apps. Streamlit. Retrieved February 3, 2025, from [https://www.streamlit.io/](https://www.streamlit.io/).

6. Virtanen, P., Gommers, R., Oliphant, T. E., et al. (2020). SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python. *Nature Methods, 17*(3), 261-272. [DOI: 10.1038/s41592-019-0686-2](https://doi.org/10.1038/s41592-019-0686-2).

7. Seabold, S., & Perktold, J. (2010). Statsmodels: Econometric and statistical modeling with Python. *Proceedings of the 9th Python in Science Conference* (pp. 92-96). Retrieved February 3, 2025, from [https://www.statsmodels.org/](https://www.statsmodels.org/).
